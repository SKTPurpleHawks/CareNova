import 'dart:async';
import 'dart:io';
import 'package:flutter/material.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';
import 'package:permission_handler/permission_handler.dart';

import 'dart:convert'; // JSON ì²˜ë¦¬
import 'package:http/http.dart' as http;
import 'package:flutter_dotenv/flutter_dotenv.dart'; // .envì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
import 'package:audio_waveforms/audio_waveforms.dart'; // audio_waveforms íŒ¨í‚¤ì§€ ì‚¬ìš©


class RecorderScreen extends StatefulWidget {
  const RecorderScreen({super.key});

  @override
  State<RecorderScreen> createState() => _RecorderScreenState();
}



class _RecorderScreenState extends State<RecorderScreen> {
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  final FlutterSoundPlayer _player = FlutterSoundPlayer();
  bool _isRecording = false;
  bool _isPlaying = false;
  String? _filePath;
  Timer? _timer;
  int _remainingTime = 30; // â³ ìµœëŒ€ 30ì´ˆ ë…¹ìŒ ì œí•œ
  List<String> _messages = []; // âœ… ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

  double _currentDecibel = -100.0;
  // ìŒì„±ì˜ ìµœëŒ€ ë³¼ë¥¨(dB) ê¸°ë¡ ë° ìµœì†Œ ì„ê³„ì¹˜ ì„¤ì •
  double _maxDecibel = -100.0;
  static const double _minDecibelThreshold = -40.0; // ì˜ˆì‹œ: -40 dB ì´ìƒì¼ ë•Œ ì˜ë¯¸ ìˆëŠ” ìŒì„±ìœ¼ë¡œ ê°„ì£¼

  @override
  void initState() {
    super.initState();
    _initRecorder();
    _initPlayer();
  }

  Future<void> _initRecorder() async {
    await _recorder.openRecorder();
    await _requestPermissions();
  }

  Future<void> _initPlayer() async {
    await _player.openPlayer();  // âœ… í”Œë ˆì´ì–´ ì´ˆê¸°í™” ì¶”ê°€
  }

  Future<void> _requestPermissions() async {
    await Permission.microphone.request();
    await Permission.storage.request();
  }

  Future<void> _startRecording() async {
    if (_isRecording) return; // âœ… ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€

    Directory? extDir = await getExternalStorageDirectory();
    if (extDir == null) {
      debugPrint("ì™¸ë¶€ ì €ì¥ì†Œ ì ‘ê·¼ ë¶ˆê°€");
      return;
    }

    String path = '${extDir.path}/recording.wav';

    await _recorder.startRecorder(
      toFile: path,
      codec: Codec.pcm16WAV, // ğŸ¤ WAV í¬ë§· ì‚¬ìš©
      sampleRate: 16000, // ğŸ¼ 16kHz ì„¤ì •
      numChannels: 1, // ğŸ”Š ëª¨ë…¸(1ì±„ë„)
    );

    _recorder.setSubscriptionDuration(const Duration(milliseconds: 100));
    _recorder.onProgress?.listen((RecordingDisposition d) {
      setState(() {
        _currentDecibel = d.decibels ?? -100.0;
      });
      // _currentDecibel ê°’ì„ ì½˜ì†”ì— ì¶œë ¥
      // debugPrint('_currentDecibel: $_currentDecibel');
    });

    setState(() {
      _isRecording = true;
      _filePath = path;
      _remainingTime = 30;
    });

    debugPrint("ë…¹ìŒëœ íŒŒì¼ ì €ì¥ ìœ„ì¹˜: $path");

    // â³ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘
    _timer = Timer.periodic(const Duration(seconds: 1), (timer) {
      setState(() {
        _remainingTime--;
      });

      if (_remainingTime <= 0) {
        _stopRecording(); // 30ì´ˆ ì´ˆê³¼ ì‹œ ìë™ ì¤‘ì§€
      }
    });
  }

  Future<void> _stopRecording() async {
    if (!_isRecording) return; // ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€

    await _recorder.stopRecorder();
    _timer?.cancel(); // â³ íƒ€ì´ë¨¸ ì •ì§€

    setState(() {
      _isRecording = false;
    });

    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(content: Text('ë…¹ìŒ ì™„ë£Œ')),
    );

     // âœ… STT ë³€í™˜ ì‹¤í–‰ (ë…¹ìŒ ì¢…ë£Œ í›„ ìë™ ì‹¤í–‰)
    if (_filePath != null) {
      String rawText = await _convertSpeechToTextWithWhisper(_filePath!);
      String refinedText = await _refineTextWithGPT(rawText); // âœ… GPTë¡œ ë³´ì •ëœ í…ìŠ¤íŠ¸

      setState(() {
        _messages.insert(0, refinedText); // ğŸ“© ì±„íŒ… í˜•ì‹ìœ¼ë¡œ UIì— í‘œì‹œ
      });
      _playTTS(refinedText);  // âœ… TTS ì‹¤í–‰
      debugPrint("ğŸ“¢ ìµœì¢… ë³€í™˜ í…ìŠ¤íŠ¸: $refinedText");
    }
  }

  Future<String> _convertSpeechToTextWithWhisper(String filePath) async {
    String apiKey = dotenv.env['OPENAI_API_KEY'] ?? '';
    final whStopwatch = Stopwatch()..start();

    if (apiKey.isEmpty) {
      debugPrint("âŒ OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return "ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.";
    }

    try {
      File audioFile = File(filePath);

      // âœ… ë…¹ìŒëœ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
      if (!await audioFile.exists()) {
        debugPrint("âŒ ë…¹ìŒëœ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: $filePath");
        return "ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.";
      }

      int fileSize = await audioFile.length();
      debugPrint("ğŸ¤ ë…¹ìŒëœ íŒŒì¼ í¬ê¸°: $fileSize bytes");

      var request = http.MultipartRequest(
        'POST',
        Uri.parse('https://api.openai.com/v1/audio/transcriptions'),
      );

      request.headers['Authorization'] = 'Bearer $apiKey';
      request.fields['model'] = 'whisper-1';
      request.fields['language'] = 'ko';
      request.files.add(await http.MultipartFile.fromPath('file', filePath));

      debugPrint("ğŸ“¡ Whisper API ìš”ì²­ ì „ì†¡ ì¤‘...");

      var response = await request.send();

      // âœ… ì‘ë‹µì´ ì •ìƒì ìœ¼ë¡œ ì™”ëŠ”ì§€ í™•ì¸
      if (response.statusCode != 200) {
        debugPrint("âŒ Whisper API ìš”ì²­ ì‹¤íŒ¨: ${response.reasonPhrase}");
        return "ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.";
      }

      String responseBody = await response.stream.bytesToString();
      whStopwatch.stop();
      debugPrint("ğŸ“ Whisper API ì‘ë‹µ(${whStopwatch.elapsedMilliseconds}ms): $responseBody");

      // âœ… JSON íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€ ë° UTF-8 ì²˜ë¦¬
      Map<String, dynamic> decodedResponse = jsonDecode(responseBody);

      // âœ… ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
      String transcribedText = decodedResponse['text']?.trim() ?? "";

      // âœ… ë³€í™˜ëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬
      if (transcribedText.isEmpty) {
        debugPrint("âŒ ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì—†ìŒ");
        return "ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.";
      }

      debugPrint("ğŸ¤ Whisper ë³€í™˜ í…ìŠ¤íŠ¸: $transcribedText");
      return transcribedText;
    } catch (e) {
      debugPrint("âŒ Whisper API ì˜¤ë¥˜: $e");
      return "ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.";
    }
  }

  Future<String> _refineTextWithGPT(String text) async {
    String apiKey = dotenv.env['OPENAI_API_KEY'] ?? '';
    final gptStopwatch = Stopwatch()..start();

    if (apiKey.isEmpty) {
      debugPrint("âŒ OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return text;
    }

    if (text.trim().isEmpty) {
      return "ì…ë ¥ëœ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.";
    }

    try {
      var response = await http.post(
        Uri.parse("https://api.openai.com/v1/chat/completions"),
        headers: {
          'Authorization': 'Bearer $apiKey',
          'Content-Type': 'application/json',
        },
        body: utf8.encode(jsonEncode({
          //"model": "gpt-4o-mini",
          "model": "gpt-4",
          "messages": [
            {
              "role": "system",
              "content": "'ì¤‘êµ­ì–´' ë‹¨ì–´ê°€ ë§ˆì§€ë§‰ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì¤‘êµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ ì¶œë ¥í•´ì¤˜. " +
                        "ë„ˆëŠ” í•œêµ­ì–´ ë¬¸ì¥ ë³´ì • ì „ë¬¸ê°€ì•¼. ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” ë°œìŒì´ ë¶€ì •í™•í•œ ì‚¬ëŒì˜ ìŒì„±ì—ì„œ ë³€í™˜ëœ ê²°ê³¼ë¡œ, " +
                        "ì˜¤íƒ€, ì˜ëª» ì¸ì‹ëœ ë‹¨ì–´, ì´ë¦„, ë¹„ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ë“¤ì´ í¬í•¨ë  ìˆ˜ ìˆì–´. " +
                        "ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ì›ë˜ ì˜ë¯¸ë¥¼ ìµœëŒ€í•œ ì‚´ë¦¬ë©´ì„œ ìì—°ìŠ¤ëŸ½ê³  ì˜¬ë°”ë¥¸ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³´ì •í•´ì¤˜. " +
                        "ë³´ì •ì´ì§€, ë„ˆê°€ ì—†ëŠ” ë§ì„ ì§€ì–´ë‚´ë©´ ì•ˆë¼."
            },
            {"role": "user", "content": text}
          ],
          "temperature": 0.2
        })),
      );

      // âœ… UTF-8 ë””ì½”ë”© ì ìš© (bodyBytes ì‚¬ìš©)
      String responseBody = utf8.decode(response.bodyBytes);
      gptStopwatch.stop();
      debugPrint("ğŸ“ GPT API ì‘ë‹µ(${gptStopwatch.elapsedMilliseconds}ms)");

      // âœ… JSON ë°ì´í„° íŒŒì‹± (íƒ€ì… ì˜¤ë¥˜ ë°©ì§€)
      Map<String, dynamic> decodedResponse = jsonDecode(responseBody);

      // âœ… ë³€í™˜ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
      if (decodedResponse.containsKey('choices') && decodedResponse['choices'].isNotEmpty) {
        String refinedText = decodedResponse['choices'][0]['message']['content'].trim();
        return refinedText;
      } else {
        return "GPT ì‘ë‹µì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.";
      }
    } catch (e) {
      debugPrint("âŒ GPT ìš”ì²­ ì˜¤ë¥˜: $e");
      return text;
    }
  }

  Future<void> _playTTS(String text) async {
    String apiKey = dotenv.env['TYPECAST_API_KEY'] ?? '';
    String apiUrl = dotenv.env['TYPECAST_VOICE_ID'] ?? '';
    String actorId = "622964d6255364be41659078";
    //String actorId = "66d01e9dbda076835c38dcc8";
    final ttsStopwatch = Stopwatch()..start();

    if (apiKey.isEmpty || apiUrl.isEmpty) {
      debugPrint("âŒ Typecast API Key ë˜ëŠ” Voice IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return;
    }

    try {
      var response = await http.post(
        Uri.parse(apiUrl),
        headers: {
          "Authorization": "Bearer $apiKey",
          "Content-Type": "application/json"
        },
        body: jsonEncode({
          "text": text,
          "lang": "auto",
          "actor_id": actorId,
          "xapi_hd": true,
          "model_version": "latest"
        }),
      );

      if (response.statusCode == 200) {
        var responseJson = jsonDecode(utf8.decode(response.bodyBytes)); // UTF-8 ë””ì½”ë”©
        debugPrint("ğŸ“ TTS API ì‘ë‹µ: $responseJson");

        if (responseJson.containsKey("result") &&
            responseJson["result"].containsKey("speak_v2_url")) {
          String speakUrl = responseJson["result"]["speak_v2_url"];
          ttsStopwatch.stop();
          debugPrint("âœ… TTS ìƒì„± ì„±ê³µ(${ttsStopwatch.elapsedMilliseconds}ms): $speakUrl");
          
          // ğŸ“¢ **ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ URL ê°€ì ¸ì˜¤ê¸°**
          String? audioUrl = await _waitForAudio(speakUrl);
          if (audioUrl != null) {
            _downloadAndPlayTTS(audioUrl);
          } else {
            debugPrint("âŒ TTS ìŒì„± íŒŒì¼ URLì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
          }
        } else {
          debugPrint("âŒ TTS ì‘ë‹µì—ì„œ speak_v2_urlì´ ëˆ„ë½ë¨.");
        }
      } else {
        debugPrint("âŒ TTS ìš”ì²­ ì‹¤íŒ¨: ${response.reasonPhrase}");
      }
    } catch (e) {
      debugPrint("âŒ Typecast API ì˜¤ë¥˜: $e");
    }
  }

  Future<String?> _waitForAudio(String speakV2Url) async {
    String apiKey = dotenv.env['TYPECAST_API_KEY'] ?? '';

    if (apiKey.isEmpty) {
      debugPrint("âŒ Typecast API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return null;
    }

    try {
      for (int i = 0; i < 10; i++) { // ìµœëŒ€ 10ì´ˆ ë™ì•ˆ ëŒ€ê¸°
        var response = await http.get(
          Uri.parse(speakV2Url),
          headers: {"Authorization": "Bearer $apiKey"},
        );

        if (response.statusCode == 200) {
          var responseJson = jsonDecode(utf8.decode(response.bodyBytes));
          String status = responseJson["result"]["status"] ?? "";

          if (status == "done") {
            return responseJson["result"]["audio_download_url"];
          } else if (status == "progress") {
            debugPrint("â³ ìŒì„± ìƒì„± ì¤‘... (1ì´ˆ í›„ ì¬ì‹œë„)");
            await Future.delayed(Duration(seconds: 1));
          } else {
            debugPrint("âŒ Unexpected status: $status");
            return null;
          }
        } else {
          debugPrint("âŒ ìŒì„± ìƒì„± ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: ${response.reasonPhrase}");
          return null;
        }
      }
    } catch (e) {
      debugPrint("âŒ ìŒì„± ìƒì„± ëŒ€ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: $e");
    }
    return null;
  }

  Future<void> _downloadAndPlayTTS(String audioUrl) async {
    Directory tempDir = await getTemporaryDirectory();
    String filePath = '${tempDir.path}/tts_output.wav';

    try {
      var response = await http.get(Uri.parse(audioUrl));
      if (response.statusCode == 200) {
        File file = File(filePath);
        await file.writeAsBytes(response.bodyBytes);
        debugPrint("âœ… ìŒì„± íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: $filePath");

        await _player.startPlayer(fromURI: filePath); // âœ… ì¦‰ì‹œ ì¬ìƒ
      } else {
        debugPrint("âŒ TTS íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‘ë‹µ ì½”ë“œ: ${response.statusCode})");
      }
    } catch (e) {
      debugPrint("âŒ TTS íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: $e");
    }
  }

  @override
  void dispose() {
    _recorder.closeRecorder();
    _player.closePlayer();
    _timer?.cancel();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    // _currentDecibel ê°’ (-100 ~ -40)ì„ 0.0 ~ 1.0ìœ¼ë¡œ ì •ê·œí™”
    double normalizedAmplitude = ((_currentDecibel + 100) / 60).clamp(0.0, 1.0);

    return Scaffold(
      appBar: AppBar(title: const Text('ì˜¤ë””ì˜¤ ë…¹ìŒê¸°')),
      body: Column(
        children: [
          // ì±„íŒ… ë©”ì‹œì§€ ì˜ì—­
          Expanded(
            child: ListView.builder(
              reverse: true, // ìµœì‹  ë©”ì‹œì§€ê°€ ìœ„ë¡œ
              itemCount: _messages.length,
              itemBuilder: (context, index) {
                return Padding(
                  padding: const EdgeInsets.symmetric(vertical: 5, horizontal: 15),
                  child: Align(
                    alignment: Alignment.centerRight, // ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” ìš°ì¸¡ ì •ë ¬
                    child: Container(
                      padding: const EdgeInsets.all(10),
                      decoration: BoxDecoration(
                        color: const Color(0xFF43C098), // ë©”ì‹œì§€ ë°°ê²½ìƒ‰
                        borderRadius: BorderRadius.circular(10),
                      ),
                      child: Text(
                        _messages[index],
                        style: const TextStyle(color: Colors.white, fontSize: 16),
                      ),
                    ),
                  ),
                );
              },
            ),
          ),

          // ë…¹ìŒ í”„ë¡œê·¸ë˜ìŠ¤ ë°” (ì±„íŒ…ê³¼ ë²„íŠ¼ ì‚¬ì´ ì¤‘ì•™ì— í¬ê²Œ)
          Container(
            width: double.infinity,
            height: 80, // ì›í•˜ëŠ” ë†’ì´
            padding: const EdgeInsets.symmetric(horizontal: 30),
            child: Stack(
              alignment: Alignment.center,
              children: [
                // ë°°ê²½ ì»¨í…Œì´ë„ˆ (íšŒìƒ‰ ë°°ê²½, ë‘¥ê·¼ ëª¨ì„œë¦¬, ê·¸ë¦¼ì íš¨ê³¼)
                Container(
                  decoration: BoxDecoration(
                    color: Colors.grey[300],
                    borderRadius: BorderRadius.circular(40),
                    boxShadow: [
                      BoxShadow(
                        color: Colors.black.withOpacity(0.1),
                        blurRadius: 6,
                        offset: const Offset(0, 3),
                      ),
                    ],
                  ),
                ),
                // ì§„í–‰ë¥  í‘œì‹œ (ë‘¥ê·¼ ëª¨ì„œë¦¬ ì ìš©)
                ClipRRect(
                  borderRadius: BorderRadius.circular(40),
                  child: LinearProgressIndicator(
                    minHeight: 80,
                    value: _isRecording ? normalizedAmplitude : 0.0,
                    valueColor: AlwaysStoppedAnimation<Color>(const Color(0xFF43C098)),
                    backgroundColor: Colors.transparent,
                  ),
                ),
                // ì¤‘ì•™ì— ë°ì‹œë²¨ í…ìŠ¤íŠ¸ í‘œì‹œ (ì˜ˆ: "-67.5 dB")
                Text(
                  _isRecording ? "${_currentDecibel.toStringAsFixed(1)} dB" : "0 dB",
                  style: const TextStyle(
                    color: Colors.white,
                    fontSize: 20,
                    fontWeight: FontWeight.bold,
                    shadows: [
                      Shadow(
                        color: Colors.black38,
                        offset: Offset(1, 1),
                        blurRadius: 2,
                      ),
                    ],
                  ),
                ),
              ],
            ),
          ),


          
          const SizedBox(height: 20),
          // ë…¹ìŒ ë²„íŠ¼ ì˜ì—­
          Padding(
            padding: const EdgeInsets.only(bottom: 30),
            child: ElevatedButton(
              onPressed: _isRecording ? _stopRecording : _startRecording,
              style: ElevatedButton.styleFrom(
                backgroundColor: _isRecording ? Colors.grey : const Color(0xFF43C098),
                shape: const CircleBorder(),
                padding: const EdgeInsets.all(28), // ë²„íŠ¼ í¬ê¸° ì¡°ì ˆ
                elevation: 8,
              ),
              child: const Icon(
                Icons.mic,
                color: Colors.white,
                size: 40,
              ),
            ),
          ),
        ],
      ),
    );
  }

}




import 'dart:async';
import 'dart:io';
import 'package:flutter/material.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';
import 'package:permission_handler/permission_handler.dart';

import 'dart:convert'; // JSON ì²˜ë¦¬
import 'package:http/http.dart' as http;
import 'package:flutter_dotenv/flutter_dotenv.dart';


class RecorderScreen extends StatefulWidget {
  const RecorderScreen({super.key});

  @override
  State<RecorderScreen> createState() => _RecorderScreenState();
}

class BarDefinition {
  final double heightFactor; // 0.0 ~ 1.0 ì‚¬ì´ ê°’, ë¶€ëª¨ ë†’ì´ì˜ ëª‡ ë°°ë¡œ í‘œì‹œí• ì§€ ê²°ì •
  final Color? color;
  BarDefinition({required this.heightFactor, this.color});
}

// ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€ê²½ë˜ëŠ” ì»¤ìŠ¤í…€ ì›¨ì´ë¸Œí¼ ìœ„ì ¯
class LiveAudioWave extends StatefulWidget {
  final List<BarDefinition> bars;
  final double width;
  final double height;
  final double spacing;

  const LiveAudioWave({
    Key? key,
    required this.bars,
    required this.width,
    required this.height,
    required this.spacing,
  }) : super(key: key);

  @override
  _LiveAudioWaveState createState() => _LiveAudioWaveState();
}
class _LiveAudioWaveState extends State<LiveAudioWave> {
  @override
  Widget build(BuildContext context) {
    return SizedBox(
      width: widget.width,
      height: widget.height,
      child: Row(
        mainAxisAlignment: MainAxisAlignment.center,
        children: widget.bars.map((bar) {
          return AnimatedContainer(
            duration: const Duration(milliseconds: 100), // ë¶€ë“œëŸ¬ìš´ ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼
            width: (widget.width - widget.spacing * (widget.bars.length - 1)) / widget.bars.length,
            height: widget.height * bar.heightFactor,
            margin: EdgeInsets.only(right: widget.spacing),
            decoration: BoxDecoration(
              color: bar.color,
              borderRadius: BorderRadius.circular(4),
            ),
          );
        }).toList(),
      ),
    );
  }
}

class _RecorderScreenState extends State<RecorderScreen> {
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  final FlutterSoundPlayer _player = FlutterSoundPlayer();
  bool _isRecording = false;
  bool _isPlaying = false;
  String? _filePath;
  Timer? _timer;
  int _remainingTime = 30; // â³ ìµœëŒ€ 30ì´ˆ ë…¹ìŒ ì œí•œ
  List<String> _messages = []; // âœ… ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
  List<BarDefinition> _bars = [];

  double _currentDecibel = -100.0; // ìŒì„±ì˜ ìµœëŒ€ ë³¼ë¥¨(dB) ê¸°ë¡ ë° ìµœì†Œ ì„ê³„ì¹˜ ì„¤ì •
  double _maxDecibel = -100.0;
  static const double _minDecibelThreshold = -30.0; // ì˜ˆì‹œ: -40 dB ì´ìƒì¼ ë•Œ ì˜ë¯¸ ìˆëŠ” ìŒì„±ìœ¼ë¡œ ê°„ì£¼

  @override
  void initState() {
    super.initState();
    _initRecorder();
    _initPlayer();
    _generateInitialWaveform();
  }

  Future<void> _initRecorder() async {
    await _recorder.openRecorder();
    await _requestPermissions();
  }

  Future<void> _initPlayer() async {
    await _player.openPlayer();  // âœ… í”Œë ˆì´ì–´ ì´ˆê¸°í™” ì¶”ê°€
  }

  Future<void> _requestPermissions() async {
    await Permission.microphone.request();
    await Permission.storage.request();
  }

  Future<void> _startRecording() async {
    if (_isRecording) return; // âœ… ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€

    _generateInitialWaveform(); 

    Directory? extDir = await getExternalStorageDirectory();
    if (extDir == null) {
      debugPrint("ì™¸ë¶€ ì €ì¥ì†Œ ì ‘ê·¼ ë¶ˆê°€");
      return;
    }

    String path = '${extDir.path}/recording.wav';

    await _recorder.startRecorder(
      toFile: path,
      codec: Codec.pcm16WAV, // ğŸ¤ WAV í¬ë§· ì‚¬ìš©
      sampleRate: 16000, // ğŸ¼ 16kHz ì„¤ì •
      numChannels: 1, // ğŸ”Š ëª¨ë…¸(1ì±„ë„)
    );

    _recorder.setSubscriptionDuration(const Duration(milliseconds: 100));
    _recorder.onProgress?.listen((RecordingDisposition d) {
      setState(() {
        _currentDecibel = d.decibels ?? -100.0;
        _updateWaveform(_currentDecibel); // âœ… ì‹¤ì‹œê°„ ì›¨ì´ë¸Œ ì—…ë°ì´íŠ¸
      });
      // _currentDecibel ê°’ì„ ì½˜ì†”ì— ì¶œë ¥
      //debugPrint('_currentDecibel: $_currentDecibel');
    });

    setState(() {
      _isRecording = true;
      _filePath = path;
      _remainingTime = 30;
    });

    debugPrint("ë…¹ìŒëœ íŒŒì¼ ì €ì¥ ìœ„ì¹˜: $path");

    // â³ 30ì´ˆ íƒ€ì´ë¨¸ ì‹œì‘
    _timer = Timer.periodic(const Duration(seconds: 1), (timer) {
      setState(() {
        _remainingTime--;
      });

      if (_remainingTime <= 0) {
        _stopRecording(); // 30ì´ˆ ì´ˆê³¼ ì‹œ ìë™ ì¤‘ì§€
      }
    });
  }

  Future<void> _stopRecording() async {
    if (!_isRecording) return; // ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€

    await _recorder.stopRecorder();
    _timer?.cancel(); // â³ íƒ€ì´ë¨¸ ì •ì§€

    setState(() {
      _isRecording = false;
      _generateInitialWaveform();
    });

    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(content: Text('ë…¹ìŒ ì™„ë£Œ')),
    );

     // âœ… STT ë³€í™˜ ì‹¤í–‰ (ë…¹ìŒ ì¢…ë£Œ í›„ ìë™ ì‹¤í–‰)
    if (_filePath != null) {
      String rawText = await _convertSpeechToTextWithWhisper(_filePath!);
      String refinedText = await _refineTextWithGPT(rawText); // âœ… GPTë¡œ ë³´ì •ëœ í…ìŠ¤íŠ¸

      setState(() {
        _messages.insert(0, refinedText); // ğŸ“© ì±„íŒ… í˜•ì‹ìœ¼ë¡œ UIì— í‘œì‹œ
      });
      _playTTS(refinedText);  // âœ… TTS ì‹¤í–‰
      debugPrint("ğŸ“¢ ìµœì¢… ë³€í™˜ í…ìŠ¤íŠ¸: $refinedText");
    }
  }

  Future<String> _convertSpeechToTextWithWhisper(String filePath) async {
    String apiKey = dotenv.env['OPENAI_API_KEY'] ?? '';
    final whStopwatch = Stopwatch()..start();

    if (apiKey.isEmpty) {
      debugPrint("âŒ OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return "ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.";
    }

    try {
      File audioFile = File(filePath);

      // âœ… ë…¹ìŒëœ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
      if (!await audioFile.exists()) {
        debugPrint("âŒ ë…¹ìŒëœ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: $filePath");
        return "ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.";
      }

      int fileSize = await audioFile.length();
      debugPrint("ğŸ¤ ë…¹ìŒëœ íŒŒì¼ í¬ê¸°: $fileSize bytes");

      var request = http.MultipartRequest(
        'POST',
        Uri.parse('https://api.openai.com/v1/audio/transcriptions'),
      );

      request.headers['Authorization'] = 'Bearer $apiKey';
      request.fields['model'] = 'whisper-1';
      request.fields['language'] = 'ko';
      request.files.add(await http.MultipartFile.fromPath('file', filePath));

      debugPrint("ğŸ“¡ Whisper API ìš”ì²­ ì „ì†¡ ì¤‘...");
      var response = await request.send();

      // âœ… ì‘ë‹µì´ ì •ìƒì ìœ¼ë¡œ ì™”ëŠ”ì§€ í™•ì¸
      if (response.statusCode != 200) {
        debugPrint("âŒ Whisper API ìš”ì²­ ì‹¤íŒ¨: ${response.reasonPhrase}");
        return "ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.";
      }

      String responseBody = await response.stream.bytesToString();
      whStopwatch.stop();
      debugPrint("ğŸ“ Whisper API ì‘ë‹µ(${whStopwatch.elapsedMilliseconds}ms): $responseBody");

      // âœ… JSON íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€ ë° UTF-8 ì²˜ë¦¬
      Map<String, dynamic> decodedResponse = jsonDecode(responseBody);

      // âœ… ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
      String transcribedText = decodedResponse['text']?.trim() ?? "";

      // âœ… ë³€í™˜ëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬
      if (transcribedText.isEmpty) {
        debugPrint("âŒ ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì—†ìŒ");
        return "ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.";
      }

      debugPrint("ğŸ¤ Whisper ë³€í™˜ í…ìŠ¤íŠ¸: $transcribedText");
      return transcribedText;
    } catch (e) {
      debugPrint("âŒ Whisper API ì˜¤ë¥˜: $e");
      return "ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.";
    }
  }

  Future<String> _refineTextWithGPT(String text) async {
    String apiKey = dotenv.env['OPENAI_API_KEY'] ?? '';
    final gptStopwatch = Stopwatch()..start();

    if (apiKey.isEmpty) {
      debugPrint("âŒ OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return text;
    }

    if (text.trim().isEmpty) {
      return "ì…ë ¥ëœ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.";
    }

    try {
      var response = await http.post(
        Uri.parse("https://api.openai.com/v1/chat/completions"),
        headers: {
          'Authorization': 'Bearer $apiKey',
          'Content-Type': 'application/json',
        },
        body: utf8.encode(jsonEncode({
          //"model": "gpt-4o-mini",
          "model": "gpt-4",
          "messages": [
            {
              "role": "system",
              "content":"ë³´ì •ì´ì§€, ë„ˆê°€ ì—†ëŠ” ë§ì„ ì§€ì–´ë‚´ë©´ ì•ˆë¼."+ 
                        "'ì¤‘êµ­ì–´' ë‹¨ì–´ê°€ ë§ˆì§€ë§‰ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì¤‘êµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ ì¶œë ¥í•´ì¤˜. " +
                        "ë„ˆëŠ” í•œêµ­ì–´ ë¬¸ì¥ ë³´ì • ì „ë¬¸ê°€ì•¼. ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” ë°œìŒì´ ë¶€ì •í™•í•œ ì‚¬ëŒì˜ ìŒì„±ì—ì„œ ë³€í™˜ëœ ê²°ê³¼ë¡œ, " +
                        "ì˜¤íƒ€, ì˜ëª» ì¸ì‹ëœ ë‹¨ì–´, ì´ë¦„, ë¹„ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ë“¤ì´ í¬í•¨ë  ìˆ˜ ìˆì–´. " +
                        "ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ì›ë˜ ì˜ë¯¸ë¥¼ ìµœëŒ€í•œ ì‚´ë¦¬ë©´ì„œ ìì—°ìŠ¤ëŸ½ê³  ì˜¬ë°”ë¥¸ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³´ì •í•´ì¤˜. "
            },
            {"role": "user", "content": text}
          ],
          "temperature": 0.2
        })),
      );

      // âœ… UTF-8 ë””ì½”ë”© ì ìš© (bodyBytes ì‚¬ìš©)
      String responseBody = utf8.decode(response.bodyBytes);
      gptStopwatch.stop();
      debugPrint("ğŸ“ GPT API ì‘ë‹µ(${gptStopwatch.elapsedMilliseconds}ms)");

      // âœ… JSON ë°ì´í„° íŒŒì‹± (íƒ€ì… ì˜¤ë¥˜ ë°©ì§€)
      Map<String, dynamic> decodedResponse = jsonDecode(responseBody);

      // âœ… ë³€í™˜ëœ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
      if (decodedResponse.containsKey('choices') && decodedResponse['choices'].isNotEmpty) {
        String refinedText = decodedResponse['choices'][0]['message']['content'].trim();
        return refinedText;
      } else {
        return "GPT ì‘ë‹µì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.";
      }
    } catch (e) {
      debugPrint("âŒ GPT ìš”ì²­ ì˜¤ë¥˜: $e");
      return text;
    }
  }

  Future<void> _playTTS(String text) async {
    String apiKey = dotenv.env['TYPECAST_API_KEY'] ?? '';
    String apiUrl = dotenv.env['TYPECAST_VOICE_ID'] ?? '';
    String actorId = "622964d6255364be41659078";
    //String actorId = "66d01e9dbda076835c38dcc8";
    final ttsStopwatch = Stopwatch()..start();

    if (apiKey.isEmpty || apiUrl.isEmpty) {
      debugPrint("âŒ Typecast API Key ë˜ëŠ” Voice IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return;
    }

    try {
      var response = await http.post(
        Uri.parse(apiUrl),
        headers: {
          "Authorization": "Bearer $apiKey",
          "Content-Type": "application/json"
        },
        body: jsonEncode({
          "text": text,
          "lang": "auto",
          "actor_id": actorId,
          "xapi_hd": true,
          "model_version": "latest"
        }),
      );

      if (response.statusCode == 200) {
        var responseJson = jsonDecode(utf8.decode(response.bodyBytes)); // UTF-8 ë””ì½”ë”©
        debugPrint("ğŸ“ TTS API ì‘ë‹µ: $responseJson");

        if (responseJson.containsKey("result") &&
            responseJson["result"].containsKey("speak_v2_url")) {
          String speakUrl = responseJson["result"]["speak_v2_url"];
          ttsStopwatch.stop();
          debugPrint("âœ… TTS ìƒì„± ì„±ê³µ(${ttsStopwatch.elapsedMilliseconds}ms): $speakUrl");
          
          // ğŸ“¢ **ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ URL ê°€ì ¸ì˜¤ê¸°**
          String? audioUrl = await _waitForAudio(speakUrl);
          if (audioUrl != null) {
            _downloadAndPlayTTS(audioUrl);
          } else {
            debugPrint("âŒ TTS ìŒì„± íŒŒì¼ URLì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
          }
        } else {
          debugPrint("âŒ TTS ì‘ë‹µì—ì„œ speak_v2_urlì´ ëˆ„ë½ë¨.");
        }
      } else {
        debugPrint("âŒ TTS ìš”ì²­ ì‹¤íŒ¨: ${response.reasonPhrase}");
      }
    } catch (e) {
      debugPrint("âŒ Typecast API ì˜¤ë¥˜: $e");
    }
  }

  Future<String?> _waitForAudio(String speakV2Url) async {
    String apiKey = dotenv.env['TYPECAST_API_KEY'] ?? '';

    if (apiKey.isEmpty) {
      debugPrint("âŒ Typecast API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return null;
    }

    try {
      for (int i = 0; i < 10; i++) { // ìµœëŒ€ 10ì´ˆ ë™ì•ˆ ëŒ€ê¸°
        var response = await http.get(
          Uri.parse(speakV2Url),
          headers: {"Authorization": "Bearer $apiKey"},
        );

        if (response.statusCode == 200) {
          var responseJson = jsonDecode(utf8.decode(response.bodyBytes));
          String status = responseJson["result"]["status"] ?? "";

          if (status == "done") {
            return responseJson["result"]["audio_download_url"];
          } else if (status == "progress") {
            debugPrint("â³ ìŒì„± ìƒì„± ì¤‘... (1ì´ˆ í›„ ì¬ì‹œë„)");
            await Future.delayed(Duration(seconds: 1));
          } else {
            debugPrint("âŒ Unexpected status: $status");
            return null;
          }
        } else {
          debugPrint("âŒ ìŒì„± ìƒì„± ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: ${response.reasonPhrase}");
          return null;
        }
      }
    } catch (e) {
      debugPrint("âŒ ìŒì„± ìƒì„± ëŒ€ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: $e");
    }
    return null;
  }

  Future<void> _downloadAndPlayTTS(String audioUrl) async {
    Directory tempDir = await getTemporaryDirectory();
    String filePath = '${tempDir.path}/tts_output.wav';

    try {
      var response = await http.get(Uri.parse(audioUrl));
      if (response.statusCode == 200) {
        File file = File(filePath);
        await file.writeAsBytes(response.bodyBytes);
        debugPrint("âœ… ìŒì„± íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: $filePath");

        await _player.startPlayer(fromURI: filePath); // âœ… ì¦‰ì‹œ ì¬ìƒ
      } else {
        debugPrint("âŒ TTS íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‘ë‹µ ì½”ë“œ: ${response.statusCode})");
      }
    } catch (e) {
      debugPrint("âŒ TTS íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: $e");
    }
  }

  @override
  void dispose() {
    _recorder.closeRecorder();
    _player.closePlayer();
    _timer?.cancel();
    super.dispose();
  }

  void _updateWaveform(double decibel) {
    setState(() {
      _bars = List.generate(20, (index) {
        double normalizedHeight = ((decibel + 100) / 100).clamp(0.1, 1.0);
        return BarDefinition(
          heightFactor: normalizedHeight,
          color: Colors.primaries[index % Colors.primaries.length],
        );
      });
    });
  }

  void _generateInitialWaveform() {
    setState(() {
      _bars = List.generate(20, (index) {
        return BarDefinition(
          heightFactor: 0.2, // ê¸°ë³¸ ë†’ì´ (ë…¹ìŒ ì „ ì´ˆê¸° ìƒíƒœ)
          color: Colors.primaries[index % Colors.primaries.length],
        );
      });
    });
  }



  @override
  Widget build(BuildContext context) {
    // _currentDecibel ê°’ (-100 ~ -40)ì„ 0.0 ~ 1.0ìœ¼ë¡œ ì •ê·œí™”
    double normalizedAmplitude = ((_currentDecibel + 100) / 60).clamp(0.0, 1.0);

    return Scaffold(
      appBar: AppBar(title: const Text('ì˜¤ë””ì˜¤ ë…¹ìŒê¸°')),
      body: Column(
        children: [
          // ì±„íŒ… ë©”ì‹œì§€ ì˜ì—­
          Expanded(
            child: ListView.builder(
              reverse: true, // ìµœì‹  ë©”ì‹œì§€ê°€ ìœ„ë¡œ
              itemCount: _messages.length,
              itemBuilder: (context, index) {
                return Padding(
                  padding: const EdgeInsets.symmetric(vertical: 5, horizontal: 15),
                  child: Align(
                    alignment: Alignment.centerRight, // ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” ìš°ì¸¡ ì •ë ¬
                    child: Container(
                      padding: const EdgeInsets.all(10),
                      decoration: BoxDecoration(
                        color: const Color(0xFF43C098), // ë©”ì‹œì§€ ë°°ê²½ìƒ‰
                        borderRadius: BorderRadius.circular(10),
                      ),
                      child: Text(
                        _messages[index],
                        style: const TextStyle(color: Colors.white, fontSize: 16),
                      ),
                    ),
                  ),
                );
              },
            ),
          ),
          // ì‹¤ì‹œê°„ ì›¨ì´ë¸Œ ë°”
          const SizedBox(height: 20),
          LiveAudioWave(
            bars: _bars,
            width: 200,
            height: 50,
            spacing: 4,
          ),
          // ë…¹ìŒ í”„ë¡œê·¸ë˜ìŠ¤ ë°” (ì±„íŒ…ê³¼ ë²„íŠ¼ ì‚¬ì´ ì¤‘ì•™ì— í¬ê²Œ)
          Container(
            width: double.infinity,
            height: 80,
            padding: const EdgeInsets.symmetric(horizontal: 30),
            child: Stack(
              alignment: Alignment.center,
              children: [
                Container(
                  decoration: BoxDecoration(
                    gradient: LinearGradient(
                      colors: [
                        Colors.blueGrey.shade200,
                        Colors.blueGrey.shade400,
                      ],
                      begin: Alignment.centerLeft,
                      end: Alignment.centerRight,
                    ),
                    borderRadius: BorderRadius.circular(40),
                    boxShadow: [
                      BoxShadow(
                        color: Colors.black.withOpacity(0.2),
                        blurRadius: 8,
                        offset: const Offset(0, 4),
                      ),
                    ],
                  ),
                ),
                Align(
                  alignment: Alignment.centerLeft,
                  child: ClipRRect(
                    borderRadius: BorderRadius.circular(40),
                    child: FractionallySizedBox(
                      widthFactor: _isRecording ? normalizedAmplitude : 0.0,
                      child: Container(
                        height: 80,
                        decoration: BoxDecoration(
                          gradient: const LinearGradient(
                            colors: [
                              Color(0xFF43C098),
                              Color(0xFF2F8F7E),
                            ],
                            begin: Alignment.centerLeft,
                            end: Alignment.centerRight,
                          ),
                          borderRadius: BorderRadius.circular(40),
                        ),
                      ),
                    ),
                  ),
                ),
                Center(
                  child: Text(
                    _isRecording ? "${_currentDecibel.toStringAsFixed(1)} dB" : "0 dB",
                    style: const TextStyle(
                      color: Colors.white,
                      fontSize: 20,
                      fontWeight: FontWeight.bold,
                      shadows: [
                        Shadow(
                          color: Colors.black38,
                          offset: Offset(1, 1),
                          blurRadius: 2,
                        ),
                      ],
                    ),
                  ),
                ),
              ],
            ),
          ),

          const SizedBox(height: 20),
          // ë…¹ìŒ ë²„íŠ¼ ì˜ì—­
          Padding(
            padding: const EdgeInsets.only(bottom: 30),
            child: ElevatedButton(
              onPressed: _isRecording ? _stopRecording : _startRecording,
              style: ElevatedButton.styleFrom(
                backgroundColor: _isRecording ? Colors.grey : const Color(0xFF43C098),
                shape: const CircleBorder(),
                padding: const EdgeInsets.all(28), // ë²„íŠ¼ í¬ê¸° ì¡°ì ˆ
                elevation: 8,
              ),
              child: const Icon(
                Icons.mic,
                color: Colors.white,
                size: 40,
              ),
            ),
          ),
        ],
      ),
    );
  }

}



void _updateWaveform(double decibel) {
    double normalizedHeight = ((decibel + 60) / 60).clamp(0.1, 1.0);
    setState(() {
      _bars = List.generate(18, (index) {
        return BarDefinition(
          heightFactor: normalizedHeight,
          color: Colors.green.shade700.withOpacity(0.8), // ì–´ë‘ìš´ ì´ˆë¡ ê³„ì—´
        );
      });
    });
  }
